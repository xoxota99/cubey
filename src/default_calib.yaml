# Sample camera calibration file.
# We want a model that allows the camera to detect what color it's looking at for each face. 
# Our ability to accurately detect those colors is very susceptible to lighting conditions, 
# so for each environment you set up the robot, you need to take a solved cube (with a known state), 
# put it in the robot, and have the robot "look" at it to rediscover what each color looks like, 
# on each of the facelets that it will be sampling throughout the solve.

# NOTE: we *still* need half-decent lighting. In low-light conditions, blue, red, yellow, all 
# look pretty much alike, and the solver will misread those colors even with calibration.

# valid range for each of these arguments is very camera-dependent. (use 'v4l2-ctl --list-ctrls')
camera: 
  CAP_PROP_FRAME_WIDTH: 640
  CAP_PROP_FRAME_HEIGHT: 480
  CAP_PROP_FPS: 60
  CAP_PROP_HUE: default
  CAP_PROP_SATURATION: default
  CAP_PROP_BRIGHTNESS: default
  CAP_PROP_GAIN: default
  CAP_PROP_CONTRAST: default
  CAP_PROP_AUTO_EXPOSURE: default
  CAP_PROP_EXPOSURE: default 

colors: {
    # specify min-max HSV brackets for each color.
    "U": { # Up (Yellow)
      min: [25,190,20],
      max: [46,255,255]
    },
    "R": { # Right (Blue)
      min: [140,109,20],
      max: [185,255,255]
    },
    "F":  { # Front (Orange)
      min: [8,170,20],
      max: [24,255,255]
    },
    "D": { # Down (White)
      min: [0,0,100],
      max: [255,60,255]
    },
    "L": { # Left (Green)
      min: [60,109,50],
      max: [100,255,255]
    },
    "B": { # Back (Red)
      min: [248,109,64],
      max: [7,255,255]
    }
}

